# Human-Face-Emotion-Recognition

Facial expression-based automatic emotion recognition is a fascinating research area that has significant 
applications in various fields such as safety, health (detection of mental illness, understanding of human behavior, 
and psychological profiling), and human-machine interfaces (biometrics). Hence, Facial emotion recognition (FER) 
is important for human-computer interactions like behavioural description. In recent years, 
researchers have been exploring different techniques to interpret and code facial expressions 
using deep learning architectures to improve prediction accuracy. 
In this project, we build an automatic facial emotion recognition (FER) via deep learning and analyse 
various architectures, databases used in these contributions. Overall, this project serves as a resource to FER using deep learning techniques.

Using the Fer2013 dataset, we developed a method for recognising human facial expressions. 
The dataset includes images labelled with seven different emotion classes.
To identify the best deep learning model for this task, we trained and compared the
performance of several deep learning models, including custom model architecture,
ResNet18, MobileNetV2, SqueezeNet1_0, and ShuffleNetV2_x1_0.

*Facial Expression Recognition 2013 Dataset* - Fer2013 ([link](https://paperswithcode.com/dataset/fer2013)) contains approximately 30,000 facial
RGB images of different expressions with size restricted to 48Ã—48, and the main labels of it can be
divided into 7 types: 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral.
